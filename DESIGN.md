# Tasuki 設計書

[Cursor ブログ「自動運転するコードベースに向けて」](https://cursor.com/ja/blog/self-driving-codebases) の知見に基づくマルチエージェント協調ハーネス「Tasuki（襷）」の設計です。

## 設計原則（記事より）

1. **アンチフラジャイル** — 個々のエージェントが失敗してもシステム全体は耐え、他エージェントがリカバリできる
2. **経験的アプローチ** — 仮説よりデータと観察に基づいて調整
3. **スループットの明示的設計** — 「常に 100%正しいコード」より、安定した少量のエラー率を受け入れ収束させる

## アーキテクチャ概要

### ロール

| ロール               | 責務                                                                         | 制約                                                                                     |
| -------------------- | ---------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------- |
| **ルートプランナー** | ユーザー指示の全スコープを担当。現状把握し、ゴールに向けた具体的タスクを提示 | 一切コーディングしない。タスクの実行者を把握しない                                       |
| **サブプランナー**   | スコープを細分化できる場合に生成。限定範囲で同様に完全な責任                 | 再帰的にサブプランナーを生成可能                                                         |
| **ワーカー**         | タスクを 1 つ引き受け、完了まで実行                                          | システム全体を把握しない。他エージェントと直接やり取りしない。専用リポジトリコピーで作業 |

### 情報の流れ

- プランナー → タスク生成 → ワーカーが取得
- ワーカー → **ハンドオフ**（1 つのドキュメント）→ タスクを依頼したプランナーに提出
- ハンドオフには「実行内容・メモ・懸念・逸脱・発見・考察・フィードバック」を含む
- グローバル同期やクロストークなしに、情報がオーナーへチェーンを遡って伝播

### 意図的に行わないこと（記事の教訓）

- **インテグレーター役は置かない** — 単一ゲートがボトルネックになるため
- **共有 coordination ファイル＋ロック** — 競合と混乱の元のため採用しない
- **100% 正しさをコミット前に要求しない** — スループットが直列化するため。ある程度の揺らぎを許容し自然収束させる

## コンポーネント

```
tasuki/
├── DESIGN.md              # 本設計書
├── README.md
├── pyproject.toml         # 依存関係
├── tasuki/
│   ├── __init__.py
│   ├── cli.py             # CLI エントリポイント（tasuki run / init / help）
│   ├── config.py          # 設定ファイル探索（.tasuki/config/ → ~/.config/tasuki/ → パッケージ内）
│   ├── llm.py             # LLM 呼び出し（Cursor CLI / OpenAI API + フォールバック + リトライ）
│   ├── planner.py         # プランナーエージェント（ルート／サブ共通）
│   ├── planner_registry.py # サブプランナー登録・永続化（sessions/<id>/planners.json）
│   ├── worker.py          # ワーカーエージェント（ツールループ: run_cmd / read_file / edit_file）
│   ├── task_store.py      # タスクの出し入れ（sessions/<id>/tasks.json）
│   ├── handoff.py         # ハンドオフ形式の検証・パース
│   ├── repo.py            # ワーカー用リポジトリコピー管理
│   ├── runner.py          # 実行ループ: ルート＋サブプランナー→タスク→ワーカー→ハンドオフ→プランナー
│   ├── log.py             # タイムスタンプ付き JSONL ログ（可観測性）
│   └── _defaults/         # パッケージ同梱デフォルト設定（tasuki init でコピー）
└── sessions/              # セッションごとのログ・state（.gitignore）
```

## LLM 呼び出し

### プロバイダー

| プロバイダー             | 概要                                                  | 認証                                  |
| ------------------------ | ----------------------------------------------------- | ------------------------------------- |
| **cursor**（デフォルト） | Cursor CLI（`agent -p`）経由。Cursor の契約内で利用可 | `agent login` または `CURSOR_API_KEY` |
| **openai**               | OpenAI API 互換（OpenAI / Azure / ローカル）          | `OPENAI_API_KEY` または `llm.api_key` |

### モデルフォールバック

モデルの上限（レート制限）に達した場合、自動でフォールバックチェーンに従い切り替えます。

```
gpt-5.2-codex-xhigh        ← Primary model
        ↓ (rate limit, after 3 retries)
opus-4.6-thinking           ← 1st fallback
        ↓ (rate limit, after 3 retries)
auto                        ← 2nd fallback (Cursor auto-select)
```

- 同一モデルで最大 3 回リトライ（エクスポネンシャルバックオフ: 2 秒 →4 秒 →8 秒、上限 60 秒）
- レート制限以外のエラーはリトライせず即座に次のモデルへ
- 全モデル失敗時は例外で通知
- `llm.fallback_models` でフォールバック順をカスタマイズ可能

### 並行数とモデル上限のバランス

並行ワーカー数（`concurrency.max_workers`）を控えめ（デフォルト 2）に設定し、モデル上限への到達を緩和しています。スループットよりも安定した継続稼働を優先します。

## 可観測性（記事で重視）

- すべてのエージェントメッセージ・システムアクション・コマンド出力を **タイムスタンプ付き** でログ
- セッションの分析・再生が可能な形式（JSONL）で保存
- 大量ログを Cursor 等に取り込みパターン発見しやすい形式

## 新鮮さの確保（長時間稼働向け）

- `scratchpad` は追記ではなく **頻繁にゼロから書き直す**
- コンテキスト上限到達時に **自動要約**
- システムプロンプトに **自己省察・アラインメント** のリマインダー
- エージェントが **方向転換・前提の見直し** をしやすいよう奨励

## プロンプト設計の指針（記事より）

- モデルが **既にできること** は指示しない。**マルチエージェント協調** や **対象ドメイン固有** の情報だけを指示
- **制約** は指示より効果的（例: "No TODOs, no partial implementations"）
- スコープ量は **具体的な数値** で（例: "Generate 20–100 tasks"）

## 実装方針

- 第一版は **Python** で実装し、反復を速くする。本番でスループットを極限まで求める場合は Rust への移植を検討
- 各マルチエージェント実行は **1 台の十分なリソースを持つマシン** 上で動作させる（分散は避ける）

## 実装メモ（v0）

- **プランナー**: 1 回の LLM 呼び出しでスコープ（ルートはユーザー指示、サブは委譲された scope）＋（あれば）ハンドオフを渡し、番号付きタスク一覧をパース。応答に「## Sub-planner delegation」と「Scope:」ブロックがあればサブプランナーを生成
- **サブプランナー**: プランナーが委譲スコープを出力すると `PlannerRegistry` に登録。同一ラウンドまたは次ラウンドでそのスコープで 1 回実行し、タスクまたはさらにサブ委譲を出力可能（再帰）
- **ワーカー**: ツールループで最大 20 イテレーション。`run_cmd`（シェルコマンド実行）、`read_file`（ファイル読み取り）、`edit_file`（全文上書き or 差分置換）を `<tool_call>` ブロックで呼び出し、`<tool_result>` で結果を受け取る。ツールコールなしの応答でハンドオフとして完了。リポジトリ外へのファイルアクセスは拒否
- **LLM**: Cursor CLI（`agent -p --output-format json -m <model>`）を subprocess で実行。OpenAI API 互換にも切替可。フォールバック・リトライは `tasuki/llm.py` の `chat()` で一元管理
- **ログ**: 全メッセージ・アクションを `sessions/<id>/harness.log` に JSONL で追記。分析・再生用
