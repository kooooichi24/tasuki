# Tasuki configuration
# Select LLM provider: openai or cursor

llm:
  # openai: OpenAI API compatible (api_key or OPENAI_API_KEY)
  # cursor: Via Cursor CLI (agent -p). No API key needed â€” uses your Cursor subscription.
  provider: cursor
  model: gpt-5.2-codex-xhigh

  # --- provider: openai ---
  # api_key: sk-...  # Falls back to OPENAI_API_KEY env var
  # base_url: https://api.openai.com/v1  # For Azure / local models

  # --- provider: cursor (install: curl https://cursor.com/install -fsS | bash) ---
  # model: gpt-5.2-codex  # See available models: agent --list-models
  # cursor_cli_path: agent  # Or set CURSOR_AGENT_PATH env var
  # cursor_timeout_sec: 600
  # api_key: ...  # Falls back to CURSOR_API_KEY or `agent login` session

  # --- Fallback (auto-switch when a model hits its rate limit) ---
  fallback_models:
    - opus-4.6-thinking
    - auto

  # --- Retry settings ---
  retry:
    max_retries: 3          # Max retries per model
    base_delay_sec: 2       # Exponential backoff (2, 4, 8... sec)
    max_delay_sec: 60       # Max delay between retries

# Target repository (workers operate on copies of this)
repo:
  path: /tmp/tasuki-test-repo  # e.g. /path/to/your/project
  # default_branch: main

# Concurrent workers (keep low to avoid hitting rate limits)
concurrency:
  max_workers: 4

# Session and logging
session:
  root: sessions              # Session directory (logs, state)
  scratchpad_rewrite_interval: 10  # Rewrite planner scratchpad every N turns (0 = disabled)
